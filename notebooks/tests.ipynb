{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../src/')\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from src.utils import load_moons, load_monk1, load_mnist, load_cup\n",
    "from src.network import Network\n",
    "from src.activations import ReLU, Tanh, Sigmoid\n",
    "from src.losses import MeanSquaredError\n",
    "from src.metrics import BinaryAccuracy, MulticlassAccuracy, MeanEuclideanError\n",
    "from src.validation import kfold_cv\n",
    "from src.callbacks import EarlyStopping\n",
    "from src.regularizers import L2\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train, x_val, x_test, y_train, y_val, y_test = load_moons(validation=True, noise=0.2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = Network(2)\n",
    "model.add_layer(8, ReLU())\n",
    "model.add_layer(1, Tanh())\n",
    "\n",
    "# create stats\n",
    "stats = model.train(train=(x_train, y_train), validation=(x_val, y_val), metric=BinaryAccuracy(), loss=MeanSquaredError(), epochs=500, eta=0.01, nesterov=0.5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "sns.lineplot(stats['train_loss'], ax=axs[0])\n",
    "sns.lineplot(stats['val_loss'], ax=axs[0])\n",
    "sns.lineplot(stats['train_acc'], ax=axs[1])\n",
    "sns.lineplot(stats['val_acc'], ax=axs[1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions = model.multiple_outputs(x_test)\n",
    "\n",
    "accuracy_score(y_test.flatten(), np.round(predictions.flatten()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train, x_val, x_test, y_train, y_val, y_test = load_monk1()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = Network(17)\n",
    "model.add_layer(6, ReLU())\n",
    "model.add_layer(1, Tanh())\n",
    "stats = model.train((x_train, y_train), (x_test, y_test), metric=BinaryAccuracy(), loss=MeanSquaredError(), epochs=1000, nesterov=0.5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "sns.lineplot(stats['train_loss'], ax=axs[0])\n",
    "sns.lineplot(stats['val_loss'], ax=axs[0])\n",
    "sns.lineplot(stats['train_acc'], ax=axs[1])\n",
    "sns.lineplot(stats['val_acc'], ax=axs[1])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = load_mnist()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = Network(64)\n",
    "model.add_layer(16, ReLU())\n",
    "model.add_layer(10, Sigmoid(0.001))\n",
    "stats = model.train(x_train, y_train, x_test, y_test, metric=MulticlassAccuracy(), loss=MeanSquaredError(), epochs=500)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "sns.lineplot(stats['train_loss'], ax=axs[0])\n",
    "sns.lineplot(stats['val_loss'], ax=axs[0])\n",
    "sns.lineplot(stats['train_acc'], ax=axs[1])\n",
    "sns.lineplot(stats['val_acc'], ax=axs[1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_cup(test_size=0.2):\n",
    "    df = pd.read_csv(\"../data/cup/cup.train\", comment=\"#\", index_col='id', skipinitialspace=True)\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "    x_train, x_val, y_train, y_val = train_test_split(scaled.drop([\"ty\", 'tx'], axis=1).values, scaled[['tx','ty']].values, test_size=0.25, random_state=42)\n",
    "    x_train = np.expand_dims(x_train, 2)\n",
    "    x_val = np.expand_dims(x_val, 2)\n",
    "    y_train = np.expand_dims(y_train, 2)\n",
    "    y_val = np.expand_dims(y_val, 2)\n",
    "\n",
    "    return x_train, x_val, y_train, y_val"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "(1119, 9, 1)"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_val, y_train, y_val = load_cup()\n",
    "x_train.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'L2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[25], line 7\u001B[0m\n\u001B[0;32m      3\u001B[0m model\u001B[38;5;241m.\u001B[39madd_layer(\u001B[38;5;241m8\u001B[39m, ReLU())\n\u001B[0;32m      4\u001B[0m model\u001B[38;5;241m.\u001B[39madd_layer(\u001B[38;5;241m2\u001B[39m, Sigmoid())\n\u001B[0;32m      6\u001B[0m stats \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mtrain((x_train, y_train), (x_val, y_val), metric\u001B[38;5;241m=\u001B[39mMeanEuclideanError(), loss\u001B[38;5;241m=\u001B[39mMeanSquaredError(), epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1000\u001B[39m, nesterov \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.9\u001B[39m,\n\u001B[1;32m----> 7\u001B[0m                     callbacks\u001B[38;5;241m=\u001B[39m[\u001B[43mL2\u001B[49m])\n",
      "\u001B[1;31mNameError\u001B[0m: name 'L2' is not defined"
     ]
    }
   ],
   "source": [
    "model = Network(9)\n",
    "model.add_layer(16, ReLU())\n",
    "model.add_layer(8, ReLU())\n",
    "model.add_layer(2, Sigmoid())\n",
    "\n",
    "stats = model.train((x_train, y_train), (x_val, y_val), metric=MeanEuclideanError(), loss=MeanSquaredError(), epochs=1000, nesterov = 0.9,\n",
    "                    callbacks=[])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "sns.lineplot(stats['train_loss'], ax=axs[0])\n",
    "sns.lineplot(stats['val_loss'], ax=axs[0])\n",
    "sns.lineplot(stats['train_acc'], ax=axs[1])\n",
    "sns.lineplot(stats['val_acc'], ax=axs[1])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test Load_Cup with kfold cross validation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "((1119, 9, 1), (1119, 2, 1))"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, x_test, y, y_test = load_cup()\n",
    "x.shape, y.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▎        | 136/1000[, loss=0.0145, val_loss=0.0145, val_acc=0.15] "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 6\u001B[0m\n\u001B[1;32m      3\u001B[0m model\u001B[38;5;241m.\u001B[39madd_layer(\u001B[38;5;241m8\u001B[39m, ReLU())\n\u001B[1;32m      4\u001B[0m model\u001B[38;5;241m.\u001B[39madd_layer(\u001B[38;5;241m2\u001B[39m, Sigmoid())\n\u001B[0;32m----> 6\u001B[0m \u001B[43mkfold_cv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mMeanEuclideanError\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mMeanSquaredError\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1000\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meta\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mEarlyStopping\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpatience\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/neural-network-from-scratch/notebooks/../src/validation.py:45\u001B[0m, in \u001B[0;36mkfold_cv\u001B[0;34m(model, x, y, k, return_mean, **kwargs)\u001B[0m\n\u001B[1;32m     42\u001B[0m x_val \u001B[38;5;241m=\u001B[39m x_folds[i]\n\u001B[1;32m     43\u001B[0m y_val \u001B[38;5;241m=\u001B[39m y_folds[i]\n\u001B[0;32m---> 45\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_val\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_val\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     46\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmetric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetric\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     47\u001B[0m \u001B[43m    \u001B[49m\u001B[43mloss\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mloss\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     48\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     49\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     50\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     51\u001B[0m \u001B[43m    \u001B[49m\u001B[43meta\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meta\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     53\u001B[0m \u001B[38;5;66;03m# compute accuracy\u001B[39;00m\n\u001B[1;32m     54\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mmultiple_outputs(x_val)\n",
      "File \u001B[0;32m~/PycharmProjects/neural-network-from-scratch/notebooks/../src/network.py:129\u001B[0m, in \u001B[0;36mNetwork.train\u001B[0;34m(self, train, validation, metric, loss, epochs, eta, batch_size, verbose, callbacks)\u001B[0m\n\u001B[1;32m    125\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__backward_prop__(deltas\u001B[38;5;241m=\u001B[39mdeltas, eta\u001B[38;5;241m=\u001B[39meta)\n\u001B[1;32m    128\u001B[0m \u001B[38;5;66;03m# compute training error and accuracy for current epoch and append stats\u001B[39;00m\n\u001B[0;32m--> 129\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mepoch_stats\u001B[49m\u001B[43m(\u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_labels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_labels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetric\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbar\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    131\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m callback \u001B[38;5;129;01min\u001B[39;00m callbacks:\n\u001B[1;32m    132\u001B[0m     callback(\u001B[38;5;28mself\u001B[39m)\n",
      "File \u001B[0;32m~/PycharmProjects/neural-network-from-scratch/notebooks/../src/network.py:154\u001B[0m, in \u001B[0;36mNetwork.epoch_stats\u001B[0;34m(self, epoch, tr, tr_labels, val, val_labels, metric, loss, verbose, bar)\u001B[0m\n\u001B[1;32m    151\u001B[0m val_metric \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    153\u001B[0m tr_loss \u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mloss(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmultiple_outputs(tr), tr_labels)\n\u001B[0;32m--> 154\u001B[0m tr_metric \u001B[38;5;241m=\u001B[39m metric(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmultiple_outputs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtr\u001B[49m\u001B[43m)\u001B[49m, tr_labels)\n\u001B[1;32m    155\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtr_stats\u001B[38;5;241m.\u001B[39mappend(tr_loss)\n\u001B[1;32m    156\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtr_err\u001B[38;5;241m.\u001B[39mappend(tr_metric)\n",
      "File \u001B[0;32m~/PycharmProjects/neural-network-from-scratch/notebooks/../src/network.py:71\u001B[0m, in \u001B[0;36mNetwork.multiple_outputs\u001B[0;34m(self, patterns)\u001B[0m\n\u001B[1;32m     69\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m patterns:\n\u001B[1;32m     70\u001B[0m     p\u001B[38;5;241m.\u001B[39mshape \u001B[38;5;241m=\u001B[39m (\u001B[38;5;28mlen\u001B[39m(p), \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m---> 71\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__forward_prop__\u001B[49m\u001B[43m(\u001B[49m\u001B[43mp\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     72\u001B[0m     outputs\u001B[38;5;241m.\u001B[39mappend(out)\n\u001B[1;32m     74\u001B[0m outputs \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(outputs)\n",
      "File \u001B[0;32m~/PycharmProjects/neural-network-from-scratch/notebooks/../src/network.py:52\u001B[0m, in \u001B[0;36mNetwork.__forward_prop__\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     50\u001B[0m out \u001B[38;5;241m=\u001B[39m x\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers:\n\u001B[0;32m---> 52\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moutput\u001B[49m\u001B[43m(\u001B[49m\u001B[43mout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[0;32m~/PycharmProjects/neural-network-from-scratch/notebooks/../src/layers.py:38\u001B[0m, in \u001B[0;36mLayer.output\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;124;03m\"\"\"Compute layer's output and save it.\"\"\"\u001B[39;00m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlast_input \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mcopy(x)\n\u001B[0;32m---> 38\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlast_net \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnet\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     39\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlast_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mactivation\u001B[38;5;241m.\u001B[39mactivation(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlast_net)\n\u001B[1;32m     41\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlast_output\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model = Network(9,)\n",
    "model.add_layer(8, ReLU())\n",
    "model.add_layer(8, ReLU())\n",
    "model.add_layer(2, Sigmoid())\n",
    "\n",
    "kfold_cv(model, x, y, k=5, metric=MeanEuclideanError(), loss=MeanSquaredError(), epochs=1000, eta=0.01, verbose=True, callbacks=[EarlyStopping(patience=100)])"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
