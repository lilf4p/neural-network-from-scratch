{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the src folder to the path\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from src.search import grid_search_cv\n",
    "from src.utils import load_cup, parse_results\n",
    "from src.validation import kfold_cv\n",
    "\n",
    "from src.network import Network\n",
    "from src.activations import ReLU, Sigmoid\n",
    "from src.losses import MeanSquaredError\n",
    "from src.metrics import MeanEuclideanError\n",
    "from src.regularizers import L1, L2\n",
    "from src.callbacks import EarlyStopping\n",
    "\n",
    "X, y, scaler = load_cup(validation=False, scale_outputs=True)\n",
    "y.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying first a coarse grid search for model selected in preliminary.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coarse grained grid search 24-16\n",
    "model = Network(9)\n",
    "model.add_layer(24, ReLU())\n",
    "model.add_layer(16, ReLU())\n",
    "model.add_layer(2, Sigmoid())\n",
    "\n",
    "gs_results = grid_search_cv(\n",
    "    model,\n",
    "    x=X,\n",
    "    y=y,\n",
    "    n_folds=3,\n",
    "    metric=MeanEuclideanError(),\n",
    "    loss=MeanSquaredError(),\n",
    "    eta=[1e-2, 1e-3, 1e-1],\n",
    "    nesterov=[0.8, 0.7, 0.5, 0.6],\n",
    "    reg_type=[L2, L1],\n",
    "    reg_val=[1e-7, 1e-8, 1e-6, 1e-5],\n",
    "    epochs=1000,\n",
    "    scaler=scaler,\n",
    "    workers=8,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "results_df = parse_results(gs_results)\n",
    "results_df.to_csv(\"../result_gs/2416_coarse.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coarse grained 32-16\n",
    "# Coarse grained grid search\n",
    "model = Network(9)\n",
    "model.add_layer(32, ReLU())\n",
    "model.add_layer(16, ReLU())\n",
    "model.add_layer(2, Sigmoid())\n",
    "\n",
    "gs_results = grid_search_cv(\n",
    "    model,\n",
    "    x=X,\n",
    "    y=y,\n",
    "    n_folds=3,\n",
    "    metric=MeanEuclideanError(),\n",
    "    loss=MeanSquaredError(),\n",
    "    eta=[1e-2, 1e-3, 1e-1],\n",
    "    nesterov=[0.8, 0.7, 0.5, 0.6],\n",
    "    reg_type=[L2, L1],\n",
    "    reg_val=[1e-7, 1e-8, 1e-6, 1e-5],\n",
    "    epochs=1000,\n",
    "    scaler=scaler,\n",
    "    workers=8,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = parse_results(gs_results)\n",
    "results_df.to_csv(\"../result_gs/3216_coarse.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing coarse results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2416 = pd.read_csv(\"../result_gs/2416_coarse.csv\", index_col=0)\n",
    "res3216 = pd.read_csv(\"../result_gs/3216_coarse.csv\", index_col=0)\n",
    "\n",
    "# putting architecture column to interpret results.\n",
    "res3216[\"arch\"] = [\"3216\" for _ in range(len(res3216))]\n",
    "res2416[\"arch\"] = [\"2416\" for _ in range(len(res2416))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print results for 24-16 architecture, sorted by mean euclidean error.\n",
    "res2416.sort_values(by=[\"val_mee\"], ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print results for 32-16 arch, sorted by best validation mee\n",
    "res3216.sort_values(by=[\"val_mee\"], ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge results and express regularizer strength in log scale to better reading\n",
    "import numpy as np\n",
    "\n",
    "res = pd.concat([res2416, res3216])\n",
    "res[\"reg_val\"] = res[\"reg_val\"].apply(lambda x: np.log10(x))\n",
    "\n",
    "# print best 10 models overall.\n",
    "res.sort_values(by=[\"val_mee\"], ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving to csv\n",
    "res.to_csv(\"../result_gs/merged_coarse.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, try with fine grid search for both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine grained grid search 24-16\n",
    "model = Network(9)\n",
    "model.add_layer(24, ReLU())\n",
    "model.add_layer(16, ReLU())\n",
    "model.add_layer(2, Sigmoid(), initializer=\"xavier\")\n",
    "\n",
    "gs_results = grid_search_cv(\n",
    "    model,\n",
    "    x=X,\n",
    "    y=y,\n",
    "    n_folds=3,\n",
    "    metric=MeanEuclideanError(),\n",
    "    loss=MeanSquaredError(),\n",
    "    eta=[0.8e-2, 1e-2, 1.2e-2, 1.4e-2],\n",
    "    nesterov=[0.5, 0.52, 0.54, 0.56, 0.58, 0.6],\n",
    "    reg_type=[L1, L2],\n",
    "    reg_val=[1e-7, 10 ** (-6.8), 10 ** (-6.6), 10 ** (-6.4), 10 ** (-6.2), 1e-6],\n",
    "    epochs=1000,\n",
    "    scaler=scaler,\n",
    "    workers=8,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = parse_results(gs_results)\n",
    "results_df.to_csv(\"../result_gs/2416_fine.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_2416 = pd.read_csv(\"../result_gs/2416_fine.csv\")\n",
    "results_2416.sort_values(by=\"val_mee\", ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine grained grid search 32-16\n",
    "model = Network(9)\n",
    "model.add_layer(32, ReLU())\n",
    "model.add_layer(16, ReLU())\n",
    "model.add_layer(2, Sigmoid(), initializer=\"xavier\")\n",
    "\n",
    "gs_results = grid_search_cv(\n",
    "    model,\n",
    "    x=X,\n",
    "    y=y,\n",
    "    n_folds=3,\n",
    "    metric=MeanEuclideanError(),\n",
    "    loss=MeanSquaredError(),\n",
    "    eta=[0.8e-2, 1e-2, 1.2e-2, 1.4e-2],\n",
    "    nesterov=[0.6, 0.62, 0.64, 0.66, 0.68, 0.7],\n",
    "    reg_type=[L1, L2],\n",
    "    reg_val=[1e-8, 10 ** (-7.8), 10 ** (-7.6), 10 ** (-7.4), 10 ** (-7.2), 1e-7],\n",
    "    epochs=1000,\n",
    "    scaler=scaler,\n",
    "    workers=6,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = parse_results(gs_results)\n",
    "results_df.to_csv(\"../result_gs/3216_fine.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_3216 = pd.read_csv(\"../result_gs/3216_fine.csv\")\n",
    "results_3216.sort_values(by=\"val_mee\", ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = parse_results(gs_results)\n",
    "results_df.sort_values(by=\"val_mee\", ascending=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### analyze fine gs results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine3216 = pd.read_csv(\"../result_gs/3216_fine.csv\", index_col=0)\n",
    "fine3216.sort_values(by=[\"val_mee\"], ascending=True).head(10)\n",
    "\n",
    "fine3216[\"arch\"] = [\"3216\" for _ in range(len(fine3216))]\n",
    "fine3216[\"reg_val\"] = fine3216[\"reg_val\"].apply(lambda x: np.log10(x))\n",
    "fine3216 = fine3216.round(4)\n",
    "fine3216.sort_values(by=[\"val_mee\"], ascending=True, inplace=True)\n",
    "fine3216.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine2416 = pd.read_csv(\"../result_gs/2416_fine.csv\", index_col=0)\n",
    "fine2416.sort_values(by=[\"val_mee\"], ascending=True).head(10)\n",
    "\n",
    "fine2416[\"arch\"] = [\"2416\" for _ in range(len(fine2416))]\n",
    "fine2416[\"reg_val\"] = fine2416[\"reg_val\"].apply(lambda x: np.log10(x))\n",
    "fine2416 = fine2416.round(4)\n",
    "fine2416.sort_values(by=[\"val_mee\"], ascending=True, inplace=True)\n",
    "fine2416.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge again and saver to csv\n",
    "fine = pd.concat([fine2416, fine3216])\n",
    "fine.to_csv(\"../result_gs/merged_fine.csv\")\n",
    "\n",
    "# show results (top 4)\n",
    "fine.sort_values(by=[\"val_mee\"], ascending=True).head(4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model Selection\n",
    "\n",
    "- 32-16 ReLU activated, Sigmoid output with Xavier initialization\n",
    "- regularizer L2, with $\\log_{10}(\\lambda) = -7.6 $ \n",
    "- learning rate  = 0.014\n",
    "- nesterov momentum $\\alpha =0.6$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing correct number of tr epochs wih 10 fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform 5-fold cross validation with best parameters to assess correct number of epochs\n",
    "X, y, scaler = load_cup(scale_outputs=True, validation=False)\n",
    "\n",
    "from src.validation import kfold_cv\n",
    "\n",
    "reg = 6.31e-8\n",
    "model = Network(9, L2(reg))\n",
    "model.add_layer(32, ReLU(), initializer=\"xavier\")\n",
    "model.add_layer(16, ReLU(), initializer=\"xavier\")\n",
    "model.add_layer(2, Sigmoid(), initializer=\"xavier\")\n",
    "\n",
    "try:\n",
    "    res = kfold_cv(\n",
    "        model,\n",
    "        X,\n",
    "        y,\n",
    "        k=10,\n",
    "        metric=MeanEuclideanError(),\n",
    "        loss=MeanSquaredError(),\n",
    "        nesterov=0.6,\n",
    "        epochs=1000,\n",
    "        eta=0.014,\n",
    "        verbose=True,\n",
    "        callbacks=[EarlyStopping(50)],\n",
    "        scaler=scaler,\n",
    "    )\n",
    "except KeyboardInterrupt:\n",
    "    model.bar.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 170 epochs needed. Now re-train model on all dev. set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = 6.31e-8\n",
    "model = Network(9, L2(reg))\n",
    "model.add_layer(32, ReLU())\n",
    "model.add_layer(16, ReLU())\n",
    "model.add_layer(2, Sigmoid(), initializer=\"xavier\")\n",
    "\n",
    "stats = model.train(\n",
    "    eta=0.014,\n",
    "    nesterov=0.6,\n",
    "    train=(X, y),\n",
    "    validation=(X, y),  # putting tr as validation, just to print the MEE.\n",
    "    metric=MeanEuclideanError(),\n",
    "    loss=MeanSquaredError(),\n",
    "    epochs=170,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally assess performance on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import load_cup_test\n",
    "X_test, y_test = load_cup_test(scaler=scaler)\n",
    "\n",
    "y_pred = model.multiple_outputs(X_test)\n",
    "\n",
    "y_pred_new = scaler.inverse_transform(\n",
    "    y_pred.reshape((y_pred.shape[0], y_pred.shape[1]))\n",
    ").reshape(y_pred.shape)\n",
    "y_test_new = scaler.inverse_transform(\n",
    "    y_test.reshape((y_test.shape[0], y_test.shape[1]))\n",
    ").reshape(y_test.shape)\n",
    "\n",
    "metric = MeanEuclideanError()\n",
    "print(\"MEE (real scale):\", metric(y_pred_new, y_test_new))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1 (main, Dec 23 2022, 09:39:26) [Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a29ded6e616d7585d61f3771ec5a363b94eb99ca2ded5b8798d9842f646a5745"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
